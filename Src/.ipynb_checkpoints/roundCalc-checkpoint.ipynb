{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier\n",
      "is in if\n",
      "      test-mae-mean  test-mae-std  train-mae-mean  train-mae-std\n",
      "0       2886.007373      4.456550     2886.016065       1.172841\n",
      "1       2742.052539      4.371791     2742.183496       1.100577\n",
      "2       2606.419287      4.247414     2606.512012       0.988036\n",
      "3       2479.553174      4.109457     2479.541601       0.762356\n",
      "4       2361.880371      3.929556     2361.835547       1.073810\n",
      "5       2253.427734      4.104824     2253.337647       1.046024\n",
      "6       2154.374951      3.795487     2154.315967       1.253383\n",
      "7       2065.360303      4.255397     2065.411084       1.673943\n",
      "8       1985.320801      3.661455     1985.181616       2.171704\n",
      "9       1913.682641      3.675978     1913.519873       2.392394\n",
      "10      1850.245630      3.414214     1849.909375       2.275843\n",
      "11      1794.409522      4.277369     1794.010010       3.287976\n",
      "12      1743.867236      4.637342     1743.446606       4.324663\n",
      "13      1698.492359      4.681446     1697.943604       4.098709\n",
      "14      1658.593970      5.518709     1657.882471       4.696780\n",
      "15      1622.409668      5.105770     1621.673657       4.056010\n",
      "16      1590.686621      5.371335     1590.041211       4.001822\n",
      "17      1562.626953      4.959060     1562.031811       3.556139\n",
      "18      1538.774438      4.717376     1537.960547       3.665043\n",
      "19      1517.013428      4.488559     1516.140600       3.606819\n",
      "20      1497.211572      4.718552     1496.369385       3.851183\n",
      "21      1480.433105      4.631109     1479.464258       3.314033\n",
      "22      1465.529346      5.015904     1464.495752       3.128110\n",
      "23      1451.995923      5.428329     1450.989062       3.522248\n",
      "24      1439.705029      5.255339     1438.648047       3.171356\n",
      "25      1430.021973      5.235661     1428.818530       3.099622\n",
      "26      1421.075244      4.807517     1419.820361       2.808675\n",
      "27      1413.348169      4.402748     1411.956201       2.027764\n",
      "28      1406.362354      4.238369     1404.912695       2.198913\n",
      "29      1400.522998      4.646745     1398.942920       2.679381\n",
      "...             ...           ...             ...            ...\n",
      "2970    1193.584155      2.876971     1138.498340       1.147573\n",
      "2971    1193.567627      2.865593     1138.468482       1.151602\n",
      "2972    1193.570166      2.864347     1138.462646       1.146296\n",
      "2973    1193.568237      2.864178     1138.456397       1.156066\n",
      "2974    1193.553564      2.856515     1138.440552       1.143505\n",
      "2975    1193.531836      2.881170     1138.414355       1.135865\n",
      "2976    1193.528028      2.874823     1138.398828       1.128355\n",
      "2977    1193.526294      2.860968     1138.383716       1.133412\n",
      "2978    1193.531836      2.850193     1138.374536       1.144402\n",
      "2979    1193.525952      2.859271     1138.358325       1.140413\n",
      "2980    1193.521729      2.850571     1138.335889       1.148957\n",
      "2981    1193.514038      2.847415     1138.307373       1.152900\n",
      "2982    1193.508325      2.840786     1138.289258       1.161349\n",
      "2983    1193.506812      2.846508     1138.265503       1.177443\n",
      "2984    1193.509204      2.848526     1138.251904       1.175604\n",
      "2985    1193.513721      2.843481     1138.238550       1.182023\n",
      "2986    1193.512183      2.832276     1138.227368       1.174914\n",
      "2987    1193.514673      2.819168     1138.203833       1.185671\n",
      "2988    1193.509668      2.826703     1138.191479       1.196583\n",
      "2989    1193.506567      2.816928     1138.173706       1.194421\n",
      "2990    1193.522632      2.812743     1138.179126       1.190656\n",
      "2991    1193.518481      2.814588     1138.161792       1.190556\n",
      "2992    1193.513257      2.810583     1138.147266       1.191722\n",
      "2993    1193.502661      2.807057     1138.117847       1.213695\n",
      "2994    1193.512280      2.806047     1138.109570       1.225049\n",
      "2995    1193.496753      2.812263     1138.085180       1.229491\n",
      "2996    1193.488843      2.819441     1138.069312       1.226301\n",
      "2997    1193.492676      2.822703     1138.057080       1.224215\n",
      "2998    1193.491211      2.819993     1138.042114       1.217718\n",
      "2999    1193.489624      2.838717     1138.020166       1.209230\n",
      "\n",
      "[3000 rows x 4 columns]\n",
      "3000\n",
      "trained\n"
     ]
    }
   ],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "#from IPython import get_ipython\n",
    "#get_ipython().magic('matplotlib inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = pd.read_csv('../Data/subset_training_crossV_1.csv',delimiter=\",\", header=0, index_col=0)\n",
    "target = 'loss'\n",
    "IDcol = 'id'\n",
    "\n",
    "\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=100):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        print \"is in if\"\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, \n",
    "                          num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds, \n",
    "                          metrics=['mae'], \n",
    "                          early_stopping_rounds=early_stopping_rounds)#, show_progress=False)\n",
    "        print cvresult\n",
    "        print cvresult.shape[0]\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Train on data\n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    final_gb = xgb.train(xgb_param, xgtrain, num_boost_round = cvresult.shape[0])\n",
    "    print \"trained\"\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['loss'],eval_metric='mae')\n",
    "    print \"Fitted\"\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    print \"Predicted\"\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    print \"Probs\"\n",
    "    \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Explained variance: %.4g\" % metrics.explained_variance_score(dtrain['loss'].values, dtrain_predictions)\n",
    "    print \"MAE (Train): %f\" % metrics.mean_absolute_error(dtrain['loss'], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "\n",
    "\n",
    "    \n",
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "#print predictors\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=3000,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.54,\n",
    " objective= 'reg:linear',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)\n",
    "print \"Classifier\"\n",
    "modelfit(xgb1, train, predictors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: -2405.00224, std: 106.83809, params: {'max_depth': 1, 'min_child_weight': 1},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 1, 'min_child_weight': 3},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 1, 'min_child_weight': 5},\n",
       "  mean: -2405.00224, std: 106.83809, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: -2405.00224, std: 106.83809, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: -2405.00224, std: 106.83809, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: -2405.00224, std: 106.83809, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: -2873.69097, std: 27.75296, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 1, 'min_child_weight': 1},\n",
       " -2405.002236807074)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(1,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = XGBClassifier( \n",
    "        learning_rate =0.05, \n",
    "        n_estimators=121, \n",
    "        max_depth=3,\n",
    "        min_child_weight=1, \n",
    "        gamma=0, \n",
    "        subsample=0.9, \n",
    "        colsample_bytree=0.53,\n",
    "        objective= 'reg:linear', \n",
    "        nthread=4, \n",
    "        scale_pos_weight=1, \n",
    "        seed=42), \n",
    "    param_grid = param_test1, scoring='neg_mean_absolute_error',n_jobs=1,iid=False, cv=2)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
