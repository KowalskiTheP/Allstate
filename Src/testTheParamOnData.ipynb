{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check 1\n",
      "RAM should be released\n",
      "CV step:  1\n",
      "CV step:  2\n",
      "CV step:  3\n",
      "CV step:  4\n",
      "CV step:  5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-184c6cdab75e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mnew_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mcompLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompLoss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mx_std_n\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompLoss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mx_std_p\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_train' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "def calc_MAE(Y, Y_hat):\n",
    "    sumVar = 0\n",
    "    for i in range(len(Y)):\n",
    "        sumVar = sumVar + abs(Y.iloc[i]-Y_hat.iloc[i])\n",
    "    mae = sumVar / len(Y)\n",
    "    return mae\n",
    "\n",
    "def genCVdata(k, dataSet, outStr):\n",
    "    subSize=int(1/k * len(dataSet))\n",
    "    new_ds = {}\n",
    "    for i in range(1,(k+1)):\n",
    "        new_ds[i] = dataSet[((i-1)*subSize):(i*subSize)].copy()\n",
    "    \n",
    "    for j in range(1,(k+1)):\n",
    "    print \"CV step: \", j\n",
    "        new_test = new_ds[j]\n",
    "        new_train = pd.DataFrame()\n",
    "        for i in range(1,6):\n",
    "            if i != j:\n",
    "                new_train = new_train.append(new_ds[i])\n",
    "\n",
    "    new_train.to_csv('../Data/CV_sets/train_'+str(j)+'_'+str(outStr)+'.csv')\n",
    "    new_test.to_csv('../Data/CV_sets/test_'+str(j)+'_'+str(outStr)+'.csv')\n",
    "    del new_test, new_train\n",
    "    \n",
    "\n",
    "#totalSum = 0\n",
    "#for cvStep in range(1,11):\n",
    "#  print \"CV step: \", cvStep\n",
    "#  Y_hat_data = \"../Pred/subset_pred_lr0.05_Fredgth0.1_crossV_\"+str(cvStep)+\".csv\"\n",
    "#  Y_data = \"../Data/subset_test_crossV_\"+str(cvStep)+\".csv\"\n",
    "#  Y_hat = pd.read_csv(Y_hat_data,delimiter=\" \", header=None, index_col=False)\n",
    "#  Y = pd.read_csv(Y_data,delimiter=\",\", header=0, index_col=0)\n",
    "#  Y_hat = Y_hat[0]\n",
    "#  Y = Y[\"loss\"]\n",
    "#  #print Y.iloc[0], Y_hat.iloc[0]\n",
    "#  #print len(Y)\n",
    "#  totalSum = totalSum + calc_MAE(Y, Y_hat)\n",
    "#  print calc_MAE(Y, Y_hat)\n",
    "\n",
    "#print totalSum/10\n",
    "\n",
    "#dataset_train = pd.read_csv('../Data/train_noOutliers.csv',delimiter=\",\", header=0)\n",
    "dataset_train = pd.read_csv('../Data/train.csv',delimiter=\",\", header=0)\n",
    "dataset_train.drop(['id','cat110','cat116'], axis=1, inplace=True)\n",
    "dataset_train = dataset_train.reindex(np.random.permutation(dataset_train.index))\n",
    "dataset_train = pd.get_dummies(dataset_train, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=True)\n",
    "dataset_train.drop(['cat22_B', 'cat55_B', 'cat63_B', 'cat74_C', 'cat75_C', 'cat88_B', 'cat89_E', 'cat89_G', 'cat89_I', 'cat90_D', 'cat90_E', 'cat90_F', 'cat90_G', 'cat91_H', 'cat92_C', 'cat92_D', 'cat92_F', 'cat92_I', 'cat94_E', 'cat94_G', 'cat96_B', 'cat96_F', 'cat97_B', 'cat97_F', 'cat99_G', 'cat99_H', 'cat99_I', 'cat99_O', 'cat99_P', 'cat99_R', 'cat99_T', 'cat100_E', 'cat101_B', 'cat101_E', 'cat101_H', 'cat101_K', 'cat101_N', 'cat102_G', 'cat103_K', 'cat103_N', 'cat104_Q', 'cat105_B', 'cat105_P', 'cat105_Q', 'cat105_R', 'cat105_S', 'cat106_B', 'cat106_O', 'cat106_P', 'cat106_R', 'cat107_B', 'cat107_R', 'cat107_S', 'cat107_U', 'cat108_C', 'cat108_F', 'cat108_J', 'cat109_AA', 'cat109_AE', 'cat109_AF', 'cat109_AG', 'cat109_AH', 'cat109_AJ', 'cat109_AK', 'cat109_AN', 'cat109_AO', 'cat109_AP', 'cat109_AQ', 'cat109_AR', 'cat109_AT', 'cat109_AU', 'cat109_AV', 'cat109_AW', 'cat109_AY', 'cat109_B', 'cat109_BA', 'cat109_BC', 'cat109_BE', 'cat109_BF', 'cat109_BG', 'cat109_BK', 'cat109_BM', 'cat109_BN', 'cat109_BP', 'cat109_BR', 'cat109_BS', 'cat109_BT', 'cat109_BV', 'cat109_BY', 'cat109_CB', 'cat109_CC', 'cat109_CE', 'cat109_CF', 'cat109_CG', 'cat109_CH', 'cat109_CI', 'cat109_CJ', 'cat109_CK', 'cat109_CL', 'cat109_H', 'cat109_J', 'cat109_K', 'cat109_O', 'cat109_P', 'cat109_Q', 'cat109_V', 'cat109_ZZ', 'cat111_B', 'cat111_D', 'cat111_F', 'cat111_Q', 'cat111_S', 'cat111_Y', 'cat112_AQ', 'cat112_AW', 'cat112_B', 'cat113_AB', 'cat113_AC', 'cat113_AL', 'cat113_AP', 'cat113_AQ', 'cat113_AR', 'cat113_B', 'cat113_BB', 'cat113_BI', 'cat113_BL', 'cat113_E', 'cat113_G', 'cat113_O', 'cat113_P', 'cat113_T', 'cat113_U', 'cat114_B', 'cat114_D', 'cat114_G', 'cat114_S', 'cat114_W', 'cat114_X', 'cat115_B', 'cat115_C', 'cat115_D', 'cat115_E', 'cat115_W', 'cat115_X'], axis=1, inplace=True)\n",
    "dataset_length = len(dataset_train.index)\n",
    "testSize = int(0.2 * dataset_length)\n",
    "\n",
    "x_std = np.std(dataset_train['loss'])\n",
    "x_std_p = 4*x_std\n",
    "x_std_n = -4*x_std\n",
    "\n",
    "print \"Check 1\"\n",
    "new_ds = {}\n",
    "for i in range(1,6):\n",
    "    new_ds[i] = dataset_train[((i-1)*testSize):(i*testSize)].copy()\n",
    "    \n",
    "del dataset_train\n",
    "print \"RAM should be released\"\n",
    "\n",
    "#new_train = {}\n",
    "#new_test = {}\n",
    "for j in range(1,6):\n",
    "    print \"CV step: \", j\n",
    "    #new_test[j] = new_ds[j]\n",
    "    #new_train[j] = pd.DataFrame()\n",
    "    new_test = new_ds[j]\n",
    "    new_train = pd.DataFrame()\n",
    "    for i in range(1,6):\n",
    "        if i != j:\n",
    "            #new_train[j] = new_train[j].append(new_ds[i])\n",
    "            new_train = new_train.append(new_ds[i])\n",
    "            #print i, len(new_train[j])\n",
    "            #print new_train[j]['loss'].iloc[i]\n",
    "    new_train.to_csv('../Data/CV_sets/train_'+str(j)+'.csv')\n",
    "    new_test.to_csv('../Data/CV_sets/test_'+str(j)+'.csv')\n",
    "    del new_test, new_train\n",
    "    \n",
    "for i in range(len(new_train[j])):\n",
    "        compLoss = float(new_train[j]['loss'].iloc[i])\n",
    "        if compLoss < x_std_n or compLoss > x_std_p:\n",
    "            ind = new_train[j].index[i]\n",
    "            new_train[j].drop(ind, axis='index', inplace=True)\n",
    "\n",
    "print \"Check 2\"\n",
    "\n",
    "param = {'max_depth':3, 'learning_rate':0.1, 'n_estimators':1000, 'silent':True, 'objective':'reg:linear', 'nthread':4, 'gamma':0, 'min_child_weight':1, 'max_delta_step':0, 'subsample':1, 'colsample_bytree':1, 'colsample_bylevel':1, 'reg_alpha':0, 'reg_lambda':1, 'scale_pos_weight':1, 'base_score':0.5, 'seed':42, 'missing':None}\n",
    "\n",
    "\n",
    "for cv in range(1,2):\n",
    "    y_train = new_train[cv].pop('loss')\n",
    "    y_test = new_test[cv].pop('loss')\n",
    "    xgtrain = xgb.DMatrix(new_train[cv], label=y_train)\n",
    "    xgtest = xgb.DMatrix(new_test[cv])#, label=y_test)\n",
    "    \n",
    "    bst = xgb.train( param, xgtrain, num_boost_round=1000)#, evallist )\n",
    "    pred = bst.predict(xgtest)\n",
    "    \n",
    "    print pred\n",
    "    \n",
    "#estimator= XGBRegressor(max_depth=3, \n",
    "#                                     learning_rate=0.1, \n",
    "#                                     n_estimators=1000, \n",
    "#                                     silent=True, \n",
    "#                                     objective='reg:linear', \n",
    "#                                     nthread=4, \n",
    "#                                     gamma=0, \n",
    "#                                     min_child_weight=1, \n",
    "#                                     max_delta_step=0, \n",
    "#                                     subsample=1, \n",
    "#                                     colsample_bytree=1, \n",
    "#                                     colsample_bylevel=1, \n",
    "#                                     reg_alpha=0, \n",
    "#                                     reg_lambda=1, \n",
    "#                                     scale_pos_weight=1, \n",
    "#                                     base_score=0.5, \n",
    "#                                     seed=42, \n",
    "#                                     missing=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumI = 0\n",
    "for i in range(len(y_test)):\n",
    "    sumI = sumI + abs(y_test.iloc[i]-pred[i])\n",
    "    \n",
    "print sumI/len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
